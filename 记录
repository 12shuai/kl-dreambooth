以下参数比较可以，其中：inside_term = -1000 * total_loss 
CUDA_VISIBLE_DEVICES=3 python3 train_dreambooth_self_play.py \
  --instance_data_dir "/mnt/CV_teamz/users/shuaixincheng/datasets/customized/dreambooth/dog5" \
  --instance_class "dog"\
  --phase1_train_steps 0\
  --phase2_train_steps 1000 \
  --output_dir dreambooth-self-play-outputs\
  --img_log_steps 200 \
  --log_checkpoints \
  --initial_learning_rate 5e-6 \
  --train_batch_size 2 \
  --no_prior_preservation \
  --gen_data_dir inputs/dreambooth_self_play_data_dir\
  --exchange_interval 10 \
  --gen_num 1 \
  --proj_name "dog5_scale_max_debug4_use_ppo_interval10_use_approximate"\
  --beta_dpo 5000\
  --loss_type "logsigmoid" \
  --train_text_encoder \
  --diff_2_weights 1 \
  --use_approximate \
  --use_ppo \
  --ppo_episilon 1e-2 \


最后的结果在“dog5_scale_max_debug4_use_ppo_interval10_use_approximate/eval”中。

缺陷：
拟合问题：
1.不用ppo测一下——发散
2.用了ppo发现容易过拟合
3.通过将生成的改为approximate变好了！！！！！



实验现象
2. 有点欠拟合，生成的很丑
  使用LCM
  检查loss——训练不稳定，中评价
    只用在diff_2上——没太大区别
    换scale_term——没太大区别，感觉更容易发散了
    ppo随时间变化（看loss项,600步的时候开始出问题）
    换步长
    用KL版本
    折扣因子&基准线？？？
    





接下来计划
1.提升欠拟合
变化weight


2.提升过拟合
  放在SDXL——提升风格化
  从能量法找答案
  使用LCM
  双向kl散度
  换成ref的预测作为kl loss——感觉变差了,因为klloss非常小，几乎不会进行优化
  试一下别的prompt，比如style——似乎没什么效果
  a photo of sbs，没有dog，然后通过某种损失将sbs和dog联系在一起（初始化，对比损失，条件log）。
  提升时间
  使用CC
  随时间变化的KL散度项（因为预测的准确率跟采样时间有关）
  想清楚如何通过
  在特定的evaluation上finetune
  插值——有效果
  如何不过拟合到toy和其他动物，其他动物都会生成到sbs，其他词不能映射到该概念！！！！！！！！！！！！！！！！！！！
  怎么让他能够有动作—，插值貌似不能完全解决



3.其他应用
  多个目标
  单图编辑


问题：
1. 不train text encoder，只有加了名词后缀才能生成，否则生成不了！！



2.构思self-play如何引入这个东西


3.为什么有的图像很好编辑